{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14.1\n",
      "11.7\n",
      "c:\\Anaconda\\envs\\pytorchenv\\python.exe\n",
      "c:\\Anaconda\\envs\\pytorchenv\\lib\\site-packages\\torch\\__init__.py\n",
      "True\n",
      "Collecting environment information...\n",
      "PyTorch version: 1.13.1\n",
      "Is debug build: False\n",
      "CUDA used to build PyTorch: 11.7\n",
      "ROCM used to build PyTorch: N/A\n",
      "\n",
      "OS: Microsoft Windows 11 Home\n",
      "GCC version: (Rev4, Built by MSYS2 project) 12.2.0\n",
      "Clang version: Could not collect\n",
      "CMake version: Could not collect\n",
      "Libc version: N/A\n",
      "\n",
      "Python version: 3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)] (64-bit runtime)\n",
      "Python platform: Windows-10-10.0.22621-SP0\n",
      "Is CUDA available: True\n",
      "CUDA runtime version: 11.7.99\n",
      "CUDA_MODULE_LOADING set to: LAZY\n",
      "GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3080 Ti Laptop GPU\n",
      "Nvidia driver version: 517.48\n",
      "cuDNN version: Could not collect\n",
      "HIP runtime version: N/A\n",
      "MIOpen runtime version: N/A\n",
      "Is XNNPACK available: True\n",
      "\n",
      "Versions of relevant libraries:\n",
      "[pip3] numpy==1.23.5\n",
      "[pip3] torch==1.13.1\n",
      "[pip3] torchaudio==0.13.1\n",
      "[pip3] torchinfo==1.7.1\n",
      "[pip3] torchvision==0.14.1\n",
      "[conda] blas                      1.0                         mkl  \n",
      "[conda] mkl                       2021.4.0           haa95532_640  \n",
      "[conda] mkl-service               2.4.0            py39h2bbff1b_0  \n",
      "[conda] mkl_fft                   1.3.1            py39h277e83a_0  \n",
      "[conda] mkl_random                1.2.2            py39hf11a4ad_0  \n",
      "[conda] numpy                     1.23.5           py39h3b20f71_0  \n",
      "[conda] numpy-base                1.23.5           py39h4da318b_0  \n",
      "[conda] pytorch                   1.13.1          py3.9_cuda11.7_cudnn8_0    pytorch\n",
      "[conda] pytorch-cuda              11.7                 h67b0de4_1    pytorch\n",
      "[conda] pytorch-mutex             1.0                        cuda    pytorch\n",
      "[conda] torchaudio                0.13.1                   pypi_0    pypi\n",
      "[conda] torchinfo                 1.7.1              pyhd8ed1ab_0    conda-forge\n",
      "[conda] torchvision               0.14.1                   pypi_0    pypi\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR\n",
    "import torchvision\n",
    "print(torchvision.__version__)\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.transforms as transforms\n",
    "print(torch.version.cuda)\n",
    "torch.cuda.is_available()\n",
    "import sys\n",
    "print(sys.executable)\n",
    "import torch\n",
    "print(torch.__file__) \n",
    "print(torch.cuda.is_available())\n",
    "from torch.utils import collect_env\n",
    "print(collect_env.main())\n",
    "from torchinfo import summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset: FashionMNIST"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training set: 60,000  \n",
    "Test set: 10,000  \n",
    "Each example: 28x28 grayscale image associated with 1 label from 10 classes.\n",
    "\n",
    "See data/shape. \n",
    "\n",
    "Note: Pytorch stores tensors in different orientation. Therefore, we convert a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0] if the PIL Image belongs to one of the modes (L, LA, P, I, F, RGB, YCbCr, RGBA, CMYK, 1) or if the numpy.ndarray has dtype = np.uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root='data/', train=True, download=True, transform=ToTensor()\n",
    ")\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root='data/', train=False, download=True, transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root='data/', train=True, download=True, transform=transform\n",
    ")\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root='data/', train=False, download=True, transform=transform\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "training_dataloader = DataLoader(dataset=training_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for X, y in training_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "NeuralNetwork_v1                         [64, 10]                  --\n",
       "├─Sequential: 1-1                        [64, 576]                 --\n",
       "│    └─Conv2d: 2-1                       [64, 1, 26, 26]           10\n",
       "│    └─ReLU: 2-2                         [64, 1, 26, 26]           --\n",
       "│    └─Conv2d: 2-3                       [64, 1, 24, 24]           10\n",
       "│    └─ReLU: 2-4                         [64, 1, 24, 24]           --\n",
       "│    └─Flatten: 2-5                      [64, 576]                 --\n",
       "├─Sequential: 1-2                        [64, 10]                  --\n",
       "│    └─Linear: 2-6                       [64, 64]                  36,928\n",
       "│    └─ReLU: 2-7                         [64, 64]                  --\n",
       "│    └─Linear: 2-8                       [64, 32]                  2,080\n",
       "│    └─ReLU: 2-9                         [64, 32]                  --\n",
       "│    └─Linear: 2-10                      [64, 10]                  330\n",
       "│    └─Softmax: 2-11                     [64, 10]                  --\n",
       "==========================================================================================\n",
       "Total params: 39,358\n",
       "Trainable params: 39,358\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 3.32\n",
       "==========================================================================================\n",
       "Input size (MB): 0.20\n",
       "Forward/backward pass size (MB): 0.70\n",
       "Params size (MB): 0.16\n",
       "Estimated Total Size (MB): 1.05\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "class NeuralNetwork_v1(nn.Module):\n",
    "    x_size = 0\n",
    "    # define the layers\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.feature_extraction = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(3,3)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(3,3)),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.dense_layers = nn.Sequential(\n",
    "            nn.Linear(in_features=576, out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=32, out_features=10),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extraction(x)\n",
    "        x_size = x.size()\n",
    "        # print(x_size)\n",
    "        logits = self.dense_layers(x)\n",
    "        return logits\n",
    "        \n",
    "model_v1 = NeuralNetwork_v1().to(device)\n",
    "summary(model_v1, input_size=(batch_size, 1, 28, 28))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "NeuralNetwork_v1_2                       [64, 10]                  --\n",
       "├─Sequential: 1-1                        [64, 784]                 --\n",
       "│    └─Conv2d: 2-1                       [64, 1, 28, 28]           10\n",
       "│    └─ReLU: 2-2                         [64, 1, 28, 28]           --\n",
       "│    └─Conv2d: 2-3                       [64, 1, 28, 28]           10\n",
       "│    └─ReLU: 2-4                         [64, 1, 28, 28]           --\n",
       "│    └─Flatten: 2-5                      [64, 784]                 --\n",
       "├─Sequential: 1-2                        [64, 10]                  --\n",
       "│    └─Linear: 2-6                       [64, 64]                  50,240\n",
       "│    └─ReLU: 2-7                         [64, 64]                  --\n",
       "│    └─Linear: 2-8                       [64, 32]                  2,080\n",
       "│    └─ReLU: 2-9                         [64, 32]                  --\n",
       "│    └─Linear: 2-10                      [64, 10]                  330\n",
       "│    └─Softmax: 2-11                     [64, 10]                  --\n",
       "==========================================================================================\n",
       "Total params: 52,670\n",
       "Trainable params: 52,670\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 4.37\n",
       "==========================================================================================\n",
       "Input size (MB): 0.20\n",
       "Forward/backward pass size (MB): 0.86\n",
       "Params size (MB): 0.21\n",
       "Estimated Total Size (MB): 1.27\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NeuralNetwork_v1_2(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.feature_extraction = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(3,3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(3,3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.dense_layers = nn.Sequential(\n",
    "            nn.Linear(in_features=28*28, out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=32, out_features=10),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.feature_extraction(x)\n",
    "        logits = self.dense_layers(x)\n",
    "        return logits\n",
    "\n",
    "model_v1_2 = NeuralNetwork_v1_2().to(device)\n",
    "summary(model_v1_2, input_size=(batch_size, 1, 28, 28))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v1_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "NeuralNetwork_v1_3                       [64, 10]                  --\n",
       "├─Sequential: 1-1                        [64, 784]                 --\n",
       "│    └─Conv2d: 2-1                       [64, 1, 28, 28]           10\n",
       "│    └─ReLU: 2-2                         [64, 1, 28, 28]           --\n",
       "│    └─Conv2d: 2-3                       [64, 1, 28, 28]           10\n",
       "│    └─ReLU: 2-4                         [64, 1, 28, 28]           --\n",
       "│    └─Flatten: 2-5                      [64, 784]                 --\n",
       "├─Sequential: 1-2                        [64, 10]                  --\n",
       "│    └─Linear: 2-6                       [64, 64]                  50,240\n",
       "│    └─ReLU: 2-7                         [64, 64]                  --\n",
       "│    └─Linear: 2-8                       [64, 64]                  4,160\n",
       "│    └─ReLU: 2-9                         [64, 64]                  --\n",
       "│    └─Linear: 2-10                      [64, 10]                  650\n",
       "│    └─Softmax: 2-11                     [64, 10]                  --\n",
       "==========================================================================================\n",
       "Total params: 55,070\n",
       "Trainable params: 55,070\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 4.53\n",
       "==========================================================================================\n",
       "Input size (MB): 0.20\n",
       "Forward/backward pass size (MB): 0.87\n",
       "Params size (MB): 0.22\n",
       "Estimated Total Size (MB): 1.29\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NeuralNetwork_v1_3(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.feature_extraction = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(3,3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(3,3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.dense_layers = nn.Sequential(\n",
    "            nn.Linear(in_features=28*28, out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=10),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.feature_extraction(x)\n",
    "        logits = self.dense_layers(x)\n",
    "        return logits\n",
    "\n",
    "model_v1_3 = NeuralNetwork_v1_3().to(device)\n",
    "summary(model_v1_3, input_size=(batch_size, 1, 28, 28))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v1_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "NeuralNetwork_v1_4                       [64, 10]                  --\n",
       "├─Sequential: 1-1                        [64, 10]                  --\n",
       "│    └─Conv2d: 2-1                       [64, 32, 28, 28]          320\n",
       "│    └─ReLU: 2-2                         [64, 32, 28, 28]          --\n",
       "│    └─Conv2d: 2-3                       [64, 64, 28, 28]          18,496\n",
       "│    └─ReLU: 2-4                         [64, 64, 28, 28]          --\n",
       "│    └─Flatten: 2-5                      [64, 50176]               --\n",
       "│    └─Linear: 2-6                       [64, 64]                  3,211,328\n",
       "│    └─ReLU: 2-7                         [64, 64]                  --\n",
       "│    └─Linear: 2-8                       [64, 64]                  4,160\n",
       "│    └─ReLU: 2-9                         [64, 64]                  --\n",
       "│    └─Linear: 2-10                      [64, 10]                  650\n",
       "│    └─Softmax: 2-11                     [64, 10]                  --\n",
       "==========================================================================================\n",
       "Total params: 3,234,954\n",
       "Trainable params: 3,234,954\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 1.15\n",
       "==========================================================================================\n",
       "Input size (MB): 0.20\n",
       "Forward/backward pass size (MB): 38.61\n",
       "Params size (MB): 12.94\n",
       "Estimated Total Size (MB): 51.75\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NeuralNetwork_v1_4(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.feature_extraction = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3,3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=28*28*64, out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=10),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.feature_extraction(x)\n",
    "        # print()\n",
    "        # logits = self.dense_layers(x)\n",
    "        return x\n",
    "\n",
    "model_v1_4 = NeuralNetwork_v1_4().to(device)\n",
    "summary(model_v1_4, input_size=(batch_size, 1, 28, 28))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v1_4_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "NeuralNetwork_v1_4_1                     [64, 10]                  --\n",
       "├─Sequential: 1-1                        [64, 10]                  --\n",
       "│    └─Conv2d: 2-1                       [64, 32, 28, 28]          320\n",
       "│    └─ReLU: 2-2                         [64, 32, 28, 28]          --\n",
       "│    └─Conv2d: 2-3                       [64, 64, 28, 28]          18,496\n",
       "│    └─ReLU: 2-4                         [64, 64, 28, 28]          --\n",
       "│    └─Flatten: 2-5                      [64, 50176]               --\n",
       "│    └─Linear: 2-6                       [64, 64]                  3,211,328\n",
       "│    └─ReLU: 2-7                         [64, 64]                  --\n",
       "│    └─Linear: 2-8                       [64, 64]                  4,160\n",
       "│    └─ReLU: 2-9                         [64, 64]                  --\n",
       "│    └─Linear: 2-10                      [64, 64]                  4,160\n",
       "│    └─ReLU: 2-11                        [64, 64]                  --\n",
       "│    └─Linear: 2-12                      [64, 10]                  650\n",
       "│    └─Softmax: 2-13                     [64, 10]                  --\n",
       "==========================================================================================\n",
       "Total params: 3,239,114\n",
       "Trainable params: 3,239,114\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 1.15\n",
       "==========================================================================================\n",
       "Input size (MB): 0.20\n",
       "Forward/backward pass size (MB): 38.64\n",
       "Params size (MB): 12.96\n",
       "Estimated Total Size (MB): 51.80\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NeuralNetwork_v1_4_1(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.feature_extraction = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3,3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=28*28*64, out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=10),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.feature_extraction(x)\n",
    "        return x\n",
    "\n",
    "model_v1_4_1 = NeuralNetwork_v1_4_1().to(device)\n",
    "summary(model_v1_4_1, input_size=(batch_size, 1, 28, 28))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v1_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "NeuralNetwork_v1_5                       [64, 10]                  --\n",
       "├─Sequential: 1-1                        [64, 100352]              --\n",
       "│    └─Conv2d: 2-1                       [64, 32, 28, 28]          320\n",
       "│    └─ReLU: 2-2                         [64, 32, 28, 28]          --\n",
       "│    └─Conv2d: 2-3                       [64, 64, 28, 28]          18,496\n",
       "│    └─ReLU: 2-4                         [64, 64, 28, 28]          --\n",
       "│    └─Conv2d: 2-5                       [64, 128, 28, 28]         73,856\n",
       "│    └─ReLU: 2-6                         [64, 128, 28, 28]         --\n",
       "│    └─Flatten: 2-7                      [64, 100352]              --\n",
       "├─Sequential: 1-2                        [64, 10]                  --\n",
       "│    └─Linear: 2-8                       [64, 64]                  6,422,592\n",
       "│    └─ReLU: 2-9                         [64, 64]                  --\n",
       "│    └─Linear: 2-10                      [64, 64]                  4,160\n",
       "│    └─ReLU: 2-11                        [64, 64]                  --\n",
       "│    └─Linear: 2-12                      [64, 10]                  650\n",
       "│    └─Softmax: 2-13                     [64, 10]                  --\n",
       "==========================================================================================\n",
       "Total params: 6,520,074\n",
       "Trainable params: 6,520,074\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 5.06\n",
       "==========================================================================================\n",
       "Input size (MB): 0.20\n",
       "Forward/backward pass size (MB): 89.99\n",
       "Params size (MB): 26.08\n",
       "Estimated Total Size (MB): 116.27\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NeuralNetwork_v1_5(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.feature_extraction = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3,3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        self.dense_layers = nn.Sequential(\n",
    "            nn.Linear(in_features=28*28*128, out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=10),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.feature_extraction(x)\n",
    "        logits = self.dense_layers(logits)\n",
    "        return logits\n",
    "\n",
    "model_v1_5 = NeuralNetwork_v1_5().to(device)\n",
    "summary(model_v1_5, input_size=(batch_size, 1, 28, 28))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v1_5_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "NeuralNetwork_v1_5_1                     [64, 10]                  --\n",
       "├─Sequential: 1-1                        [64, 100352]              --\n",
       "│    └─Conv2d: 2-1                       [64, 32, 28, 28]          320\n",
       "│    └─ReLU: 2-2                         [64, 32, 28, 28]          --\n",
       "│    └─Conv2d: 2-3                       [64, 64, 28, 28]          18,496\n",
       "│    └─ReLU: 2-4                         [64, 64, 28, 28]          --\n",
       "│    └─Conv2d: 2-5                       [64, 128, 28, 28]         73,856\n",
       "│    └─ReLU: 2-6                         [64, 128, 28, 28]         --\n",
       "│    └─Flatten: 2-7                      [64, 100352]              --\n",
       "├─Sequential: 1-2                        [64, 10]                  --\n",
       "│    └─Linear: 2-8                       [64, 64]                  6,422,592\n",
       "│    └─ReLU: 2-9                         [64, 64]                  --\n",
       "│    └─Linear: 2-10                      [64, 64]                  4,160\n",
       "│    └─ReLU: 2-11                        [64, 64]                  --\n",
       "│    └─Linear: 2-12                      [64, 64]                  4,160\n",
       "│    └─ReLU: 2-13                        [64, 64]                  --\n",
       "│    └─Linear: 2-14                      [64, 10]                  650\n",
       "│    └─Softmax: 2-15                     [64, 10]                  --\n",
       "==========================================================================================\n",
       "Total params: 6,524,234\n",
       "Trainable params: 6,524,234\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 5.06\n",
       "==========================================================================================\n",
       "Input size (MB): 0.20\n",
       "Forward/backward pass size (MB): 90.02\n",
       "Params size (MB): 26.10\n",
       "Estimated Total Size (MB): 116.32\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NeuralNetwork_v1_5_1(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.feature_extraction = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3,3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "        self.dense_layers = nn.Sequential(\n",
    "            nn.Linear(in_features=28*28*128, out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=10),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.feature_extraction(x)\n",
    "        logits = self.dense_layers(logits)\n",
    "        return logits\n",
    "\n",
    "model_v1_5_1 = NeuralNetwork_v1_5_1().to(device)\n",
    "summary(model_v1_5_1, input_size=(batch_size, 1, 28, 28))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v1_5_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "NeuralNetwork_v1_5_2                     [64, 10]                  --\n",
       "├─Sequential: 1-1                        [64, 100352]              --\n",
       "│    └─Conv2d: 2-1                       [64, 32, 28, 28]          320\n",
       "│    └─ReLU: 2-2                         [64, 32, 28, 28]          --\n",
       "│    └─Conv2d: 2-3                       [64, 64, 28, 28]          18,496\n",
       "│    └─ReLU: 2-4                         [64, 64, 28, 28]          --\n",
       "│    └─Conv2d: 2-5                       [64, 128, 28, 28]         73,856\n",
       "│    └─ReLU: 2-6                         [64, 128, 28, 28]         --\n",
       "│    └─Flatten: 2-7                      [64, 100352]              --\n",
       "├─Sequential: 1-2                        [64, 10]                  --\n",
       "│    └─Linear: 2-8                       [64, 64]                  6,422,592\n",
       "│    └─ReLU: 2-9                         [64, 64]                  --\n",
       "│    └─Linear: 2-10                      [64, 64]                  4,160\n",
       "│    └─ReLU: 2-11                        [64, 64]                  --\n",
       "│    └─Linear: 2-12                      [64, 10]                  650\n",
       "│    └─Softmax: 2-13                     [64, 10]                  --\n",
       "==========================================================================================\n",
       "Total params: 6,520,074\n",
       "Trainable params: 6,520,074\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 5.06\n",
       "==========================================================================================\n",
       "Input size (MB): 0.20\n",
       "Forward/backward pass size (MB): 89.99\n",
       "Params size (MB): 26.08\n",
       "Estimated Total Size (MB): 116.27\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NeuralNetwork_v1_5_2(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.feature_extraction = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3,3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        self.dense_layers = nn.Sequential(\n",
    "            nn.Linear(in_features=28*28*128, out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=10),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.feature_extraction(x)\n",
    "        logits = self.dense_layers(logits)\n",
    "        return logits\n",
    "\n",
    "model_v1_5_2 = NeuralNetwork_v1_5_2().to(device)\n",
    "summary(model_v1_5_2, input_size=(batch_size, 1, 28, 28))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v1_5_2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "NeuralNetwork_v1_5_2b                    [64, 10]                  --\n",
       "├─Sequential: 1-1                        [64, 100352]              --\n",
       "│    └─Conv2d: 2-1                       [64, 32, 28, 28]          320\n",
       "│    └─ReLU: 2-2                         [64, 32, 28, 28]          --\n",
       "│    └─Conv2d: 2-3                       [64, 64, 28, 28]          18,496\n",
       "│    └─ReLU: 2-4                         [64, 64, 28, 28]          --\n",
       "│    └─Conv2d: 2-5                       [64, 128, 28, 28]         73,856\n",
       "│    └─ReLU: 2-6                         [64, 128, 28, 28]         --\n",
       "│    └─Flatten: 2-7                      [64, 100352]              --\n",
       "├─Sequential: 1-2                        [64, 10]                  --\n",
       "│    └─Linear: 2-8                       [64, 128]                 12,845,184\n",
       "│    └─ReLU: 2-9                         [64, 128]                 --\n",
       "│    └─Linear: 2-10                      [64, 64]                  8,256\n",
       "│    └─ReLU: 2-11                        [64, 64]                  --\n",
       "│    └─Linear: 2-12                      [64, 10]                  650\n",
       "│    └─Softmax: 2-13                     [64, 10]                  --\n",
       "==========================================================================================\n",
       "Total params: 12,946,762\n",
       "Trainable params: 12,946,762\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 5.47\n",
       "==========================================================================================\n",
       "Input size (MB): 0.20\n",
       "Forward/backward pass size (MB): 90.02\n",
       "Params size (MB): 51.79\n",
       "Estimated Total Size (MB): 142.01\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NeuralNetwork_v1_5_2b(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.feature_extraction = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3,3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        self.dense_layers = nn.Sequential(\n",
    "            nn.Linear(in_features=28*28*128, out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=128, out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=10),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.feature_extraction(x)\n",
    "        logits = self.dense_layers(logits)\n",
    "        return logits\n",
    "\n",
    "model_v1_5_2b = NeuralNetwork_v1_5_2b().to(device)\n",
    "summary(model_v1_5_2b, input_size=(batch_size, 1, 28, 28))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v1_5_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "NeuralNetwork_v1_5_3                     [64, 10]                  --\n",
       "├─Sequential: 1-1                        [64, 100352]              --\n",
       "│    └─Conv2d: 2-1                       [64, 32, 28, 28]          320\n",
       "│    └─Conv2d: 2-2                       [64, 32, 28, 28]          9,248\n",
       "│    └─ReLU: 2-3                         [64, 32, 28, 28]          --\n",
       "│    └─Conv2d: 2-4                       [64, 64, 28, 28]          18,496\n",
       "│    └─Conv2d: 2-5                       [64, 64, 28, 28]          36,928\n",
       "│    └─ReLU: 2-6                         [64, 64, 28, 28]          --\n",
       "│    └─Conv2d: 2-7                       [64, 128, 28, 28]         73,856\n",
       "│    └─Conv2d: 2-8                       [64, 128, 28, 28]         147,584\n",
       "│    └─ReLU: 2-9                         [64, 128, 28, 28]         --\n",
       "│    └─Flatten: 2-10                     [64, 100352]              --\n",
       "├─Sequential: 1-2                        [64, 10]                  --\n",
       "│    └─Linear: 2-11                      [64, 128]                 12,845,184\n",
       "│    └─ReLU: 2-12                        [64, 128]                 --\n",
       "│    └─Linear: 2-13                      [64, 64]                  8,256\n",
       "│    └─ReLU: 2-14                        [64, 64]                  --\n",
       "│    └─Linear: 2-15                      [64, 10]                  650\n",
       "│    └─Softmax: 2-16                     [64, 10]                  --\n",
       "==========================================================================================\n",
       "Total params: 13,140,522\n",
       "Trainable params: 13,140,522\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 15.19\n",
       "==========================================================================================\n",
       "Input size (MB): 0.20\n",
       "Forward/backward pass size (MB): 179.93\n",
       "Params size (MB): 52.56\n",
       "Estimated Total Size (MB): 232.70\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NeuralNetwork_v1_5_3(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.feature_extraction = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3,3), padding='same'),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3,3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3), padding='same'),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), padding='same'),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3,3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        self.dense_layers = nn.Sequential(\n",
    "            nn.Linear(in_features=28*28*128, out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=128, out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=10),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.feature_extraction(x)\n",
    "        logits = self.dense_layers(logits)\n",
    "        return logits\n",
    "\n",
    "model_v1_5_3 = NeuralNetwork_v1_5_3().to(device)\n",
    "summary(model_v1_5_3, input_size=(batch_size, 1, 28, 28))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v1_5_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "NeuralNetwork_v1_5_4                     [64, 10]                  --\n",
       "├─Sequential: 1-1                        [64, 100352]              --\n",
       "│    └─Conv2d: 2-1                       [64, 32, 28, 28]          320\n",
       "│    └─Conv2d: 2-2                       [64, 32, 28, 28]          9,248\n",
       "│    └─ReLU: 2-3                         [64, 32, 28, 28]          --\n",
       "│    └─Conv2d: 2-4                       [64, 64, 28, 28]          18,496\n",
       "│    └─Conv2d: 2-5                       [64, 64, 28, 28]          36,928\n",
       "│    └─ReLU: 2-6                         [64, 64, 28, 28]          --\n",
       "│    └─Conv2d: 2-7                       [64, 128, 28, 28]         73,856\n",
       "│    └─Conv2d: 2-8                       [64, 128, 28, 28]         147,584\n",
       "│    └─ReLU: 2-9                         [64, 128, 28, 28]         --\n",
       "│    └─Flatten: 2-10                     [64, 100352]              --\n",
       "├─Sequential: 1-2                        [64, 10]                  --\n",
       "│    └─Linear: 2-11                      [64, 128]                 12,845,184\n",
       "│    └─ReLU: 2-12                        [64, 128]                 --\n",
       "│    └─Linear: 2-13                      [64, 128]                 16,512\n",
       "│    └─ReLU: 2-14                        [64, 128]                 --\n",
       "│    └─Linear: 2-15                      [64, 10]                  1,290\n",
       "│    └─Softmax: 2-16                     [64, 10]                  --\n",
       "==========================================================================================\n",
       "Total params: 13,149,418\n",
       "Trainable params: 13,149,418\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 15.20\n",
       "==========================================================================================\n",
       "Input size (MB): 0.20\n",
       "Forward/backward pass size (MB): 179.97\n",
       "Params size (MB): 52.60\n",
       "Estimated Total Size (MB): 232.77\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Increasing num of elt in dense layer\n",
    "class NeuralNetwork_v1_5_4(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.feature_extraction = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3,3), padding='same'),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3,3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3), padding='same'),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), padding='same'),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3,3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        self.dense_layers = nn.Sequential(\n",
    "            nn.Linear(in_features=28*28*128, out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=128, out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=128, out_features=10),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.feature_extraction(x)\n",
    "        logits = self.dense_layers(logits)\n",
    "        return logits\n",
    "\n",
    "model_v1_5_4 = NeuralNetwork_v1_5_4().to(device)\n",
    "summary(model_v1_5_4, input_size=(batch_size, 1, 28, 28))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v1_5_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "NeuralNetwork_v1_5_5                     [64, 10]                  --\n",
       "├─Sequential: 1-1                        [64, 100352]              --\n",
       "│    └─Conv2d: 2-1                       [64, 32, 28, 28]          320\n",
       "│    └─Conv2d: 2-2                       [64, 32, 28, 28]          9,248\n",
       "│    └─ReLU: 2-3                         [64, 32, 28, 28]          --\n",
       "│    └─Conv2d: 2-4                       [64, 64, 28, 28]          18,496\n",
       "│    └─Conv2d: 2-5                       [64, 64, 28, 28]          36,928\n",
       "│    └─ReLU: 2-6                         [64, 64, 28, 28]          --\n",
       "│    └─Conv2d: 2-7                       [64, 128, 28, 28]         73,856\n",
       "│    └─Conv2d: 2-8                       [64, 128, 28, 28]         147,584\n",
       "│    └─ReLU: 2-9                         [64, 128, 28, 28]         --\n",
       "│    └─Flatten: 2-10                     [64, 100352]              --\n",
       "├─Sequential: 1-2                        [64, 10]                  --\n",
       "│    └─Linear: 2-11                      [64, 256]                 25,690,368\n",
       "│    └─ReLU: 2-12                        [64, 256]                 --\n",
       "│    └─Linear: 2-13                      [64, 64]                  16,448\n",
       "│    └─ReLU: 2-14                        [64, 64]                  --\n",
       "│    └─Linear: 2-15                      [64, 10]                  650\n",
       "│    └─Softmax: 2-16                     [64, 10]                  --\n",
       "==========================================================================================\n",
       "Total params: 25,993,898\n",
       "Trainable params: 25,993,898\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 16.02\n",
       "==========================================================================================\n",
       "Input size (MB): 0.20\n",
       "Forward/backward pass size (MB): 180.00\n",
       "Params size (MB): 103.98\n",
       "Estimated Total Size (MB): 284.18\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Increasing num of elt in 1st layer 128->258. Reducing 2nd dense layer 128 -> 64\n",
    "class NeuralNetwork_v1_5_5(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.feature_extraction = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3,3), padding='same'),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3,3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3), padding='same'),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), padding='same'),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3,3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        self.dense_layers = nn.Sequential(\n",
    "            nn.Linear(in_features=28*28*128, out_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=256, out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=10),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.feature_extraction(x)\n",
    "        logits = self.dense_layers(logits)\n",
    "        return logits\n",
    "\n",
    "model_v1_5_5 = NeuralNetwork_v1_5_5().to(device)\n",
    "summary(model_v1_5_5, input_size=(batch_size, 1, 28, 28))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v1_5_5_BN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "NeuralNetwork_v1_5_5_BN                  [64, 10]                  --\n",
       "├─Sequential: 1-1                        [64, 100352]              --\n",
       "│    └─Conv2d: 2-1                       [64, 32, 28, 28]          320\n",
       "│    └─Conv2d: 2-2                       [64, 32, 28, 28]          9,248\n",
       "│    └─BatchNorm2d: 2-3                  [64, 32, 28, 28]          64\n",
       "│    └─ReLU: 2-4                         [64, 32, 28, 28]          --\n",
       "│    └─Conv2d: 2-5                       [64, 64, 28, 28]          18,496\n",
       "│    └─Conv2d: 2-6                       [64, 64, 28, 28]          36,928\n",
       "│    └─BatchNorm2d: 2-7                  [64, 64, 28, 28]          128\n",
       "│    └─ReLU: 2-8                         [64, 64, 28, 28]          --\n",
       "│    └─Conv2d: 2-9                       [64, 128, 28, 28]         73,856\n",
       "│    └─Conv2d: 2-10                      [64, 128, 28, 28]         147,584\n",
       "│    └─BatchNorm2d: 2-11                 [64, 128, 28, 28]         256\n",
       "│    └─ReLU: 2-12                        [64, 128, 28, 28]         --\n",
       "│    └─Flatten: 2-13                     [64, 100352]              --\n",
       "├─Sequential: 1-2                        [64, 10]                  --\n",
       "│    └─Linear: 2-14                      [64, 256]                 25,690,368\n",
       "│    └─BatchNorm1d: 2-15                 [64, 256]                 512\n",
       "│    └─ReLU: 2-16                        [64, 256]                 --\n",
       "│    └─Linear: 2-17                      [64, 64]                  16,448\n",
       "│    └─BatchNorm1d: 2-18                 [64, 64]                  128\n",
       "│    └─ReLU: 2-19                        [64, 64]                  --\n",
       "│    └─Linear: 2-20                      [64, 10]                  650\n",
       "│    └─Softmax: 2-21                     [64, 10]                  --\n",
       "==========================================================================================\n",
       "Total params: 25,994,986\n",
       "Trainable params: 25,994,986\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 16.02\n",
       "==========================================================================================\n",
       "Input size (MB): 0.20\n",
       "Forward/backward pass size (MB): 270.08\n",
       "Params size (MB): 103.98\n",
       "Estimated Total Size (MB): 374.26\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding BN before every activation layer.\n",
    "class NeuralNetwork_v1_5_5_BN(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.feature_extraction = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3,3), padding='same'),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3,3), padding='same'),\n",
    "            nn.BatchNorm2d(num_features=32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3), padding='same'),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,3), padding='same'),\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), padding='same'),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3,3), padding='same'),\n",
    "            nn.BatchNorm2d(num_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        self.dense_layers = nn.Sequential(\n",
    "            nn.Linear(in_features=28*28*128, out_features=256),\n",
    "            nn.BatchNorm1d(num_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=256, out_features=64),\n",
    "            nn.BatchNorm1d(num_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=10),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.feature_extraction(x)\n",
    "        logits = self.dense_layers(logits)\n",
    "        return logits\n",
    "\n",
    "model_v1_5_5_BN = NeuralNetwork_v1_5_5_BN().to(device)\n",
    "summary(model_v1_5_5_BN, input_size=(batch_size, 1, 28, 28))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v1_5_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "NeuralNetwork_v1_5_6                     [64, 10]                  --\n",
       "├─Sequential: 1-1                        [64, 100352]              --\n",
       "│    └─Conv2d: 2-1                       [64, 32, 28, 28]          320\n",
       "│    └─Conv2d: 2-2                       [64, 32, 28, 28]          9,248\n",
       "│    └─BatchNorm2d: 2-3                  [64, 32, 28, 28]          64\n",
       "│    └─ReLU: 2-4                         [64, 32, 28, 28]          --\n",
       "│    └─Dropout: 2-5                      [64, 32, 28, 28]          --\n",
       "│    └─Conv2d: 2-6                       [64, 64, 28, 28]          18,496\n",
       "│    └─Conv2d: 2-7                       [64, 64, 28, 28]          36,928\n",
       "│    └─BatchNorm2d: 2-8                  [64, 64, 28, 28]          128\n",
       "│    └─ReLU: 2-9                         [64, 64, 28, 28]          --\n",
       "│    └─Dropout: 2-10                     [64, 64, 28, 28]          --\n",
       "│    └─Conv2d: 2-11                      [64, 128, 28, 28]         73,856\n",
       "│    └─Conv2d: 2-12                      [64, 128, 28, 28]         147,584\n",
       "│    └─BatchNorm2d: 2-13                 [64, 128, 28, 28]         256\n",
       "│    └─ReLU: 2-14                        [64, 128, 28, 28]         --\n",
       "│    └─Dropout: 2-15                     [64, 128, 28, 28]         --\n",
       "│    └─Flatten: 2-16                     [64, 100352]              --\n",
       "├─Sequential: 1-2                        [64, 10]                  --\n",
       "│    └─Linear: 2-17                      [64, 256]                 25,690,368\n",
       "│    └─BatchNorm1d: 2-18                 [64, 256]                 512\n",
       "│    └─ReLU: 2-19                        [64, 256]                 --\n",
       "│    └─Dropout: 2-20                     [64, 256]                 --\n",
       "│    └─Linear: 2-21                      [64, 64]                  16,448\n",
       "│    └─BatchNorm1d: 2-22                 [64, 64]                  128\n",
       "│    └─ReLU: 2-23                        [64, 64]                  --\n",
       "│    └─Dropout: 2-24                     [64, 64]                  --\n",
       "│    └─Linear: 2-25                      [64, 10]                  650\n",
       "│    └─Softmax: 2-26                     [64, 10]                  --\n",
       "==========================================================================================\n",
       "Total params: 25,994,986\n",
       "Trainable params: 25,994,986\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 16.02\n",
       "==========================================================================================\n",
       "Input size (MB): 0.20\n",
       "Forward/backward pass size (MB): 270.08\n",
       "Params size (MB): 103.98\n",
       "Estimated Total Size (MB): 374.26\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding dropout after activations.\n",
    "class NeuralNetwork_v1_5_6(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.feature_extraction = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3,3), padding='same'),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3,3), padding='same'),\n",
    "            nn.BatchNorm2d(num_features=32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3), padding='same'),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,3), padding='same'),\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), padding='same'),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3,3), padding='same'),\n",
    "            nn.BatchNorm2d(num_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        self.dense_layers = nn.Sequential(\n",
    "            nn.Linear(in_features=28*28*128, out_features=256),\n",
    "            nn.BatchNorm1d(num_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=256, out_features=64),\n",
    "            nn.BatchNorm1d(num_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=64, out_features=10),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.feature_extraction(x)\n",
    "        logits = self.dense_layers(logits)\n",
    "        return logits\n",
    "\n",
    "model_v1_5_6 = NeuralNetwork_v1_5_6().to(device)\n",
    "summary(model_v1_5_6, input_size=(batch_size, 1, 28, 28))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v1_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "NeuralNetwork_v1_6                       [64, 10]                  --\n",
       "├─Sequential: 1-1                        [64, 401408]              --\n",
       "│    └─Conv2d: 2-1                       [64, 32, 28, 28]          320\n",
       "│    └─Conv2d: 2-2                       [64, 32, 28, 28]          9,248\n",
       "│    └─BatchNorm2d: 2-3                  [64, 32, 28, 28]          64\n",
       "│    └─ReLU: 2-4                         [64, 32, 28, 28]          --\n",
       "│    └─Conv2d: 2-5                       [64, 64, 28, 28]          18,496\n",
       "│    └─Conv2d: 2-6                       [64, 64, 28, 28]          36,928\n",
       "│    └─BatchNorm2d: 2-7                  [64, 64, 28, 28]          128\n",
       "│    └─ReLU: 2-8                         [64, 64, 28, 28]          --\n",
       "│    └─Conv2d: 2-9                       [64, 128, 28, 28]         73,856\n",
       "│    └─Conv2d: 2-10                      [64, 128, 28, 28]         147,584\n",
       "│    └─BatchNorm2d: 2-11                 [64, 128, 28, 28]         256\n",
       "│    └─ReLU: 2-12                        [64, 128, 28, 28]         --\n",
       "│    └─Conv2d: 2-13                      [64, 256, 28, 28]         295,168\n",
       "│    └─Conv2d: 2-14                      [64, 256, 28, 28]         590,080\n",
       "│    └─BatchNorm2d: 2-15                 [64, 256, 28, 28]         512\n",
       "│    └─ReLU: 2-16                        [64, 256, 28, 28]         --\n",
       "│    └─Conv2d: 2-17                      [64, 512, 28, 28]         1,180,160\n",
       "│    └─Conv2d: 2-18                      [64, 512, 28, 28]         2,359,808\n",
       "│    └─BatchNorm2d: 2-19                 [64, 512, 28, 28]         1,024\n",
       "│    └─ReLU: 2-20                        [64, 512, 28, 28]         --\n",
       "│    └─Flatten: 2-21                     [64, 401408]              --\n",
       "├─Sequential: 1-2                        [64, 10]                  --\n",
       "│    └─Linear: 2-22                      [64, 256]                 102,760,704\n",
       "│    └─BatchNorm1d: 2-23                 [64, 256]                 512\n",
       "│    └─ReLU: 2-24                        [64, 256]                 --\n",
       "│    └─Linear: 2-25                      [64, 64]                  16,448\n",
       "│    └─BatchNorm1d: 2-26                 [64, 64]                  128\n",
       "│    └─ReLU: 2-27                        [64, 64]                  --\n",
       "│    └─Linear: 2-28                      [64, 10]                  650\n",
       "│    └─Softmax: 2-29                     [64, 10]                  --\n",
       "==========================================================================================\n",
       "Total params: 107,492,074\n",
       "Trainable params: 107,492,074\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 242.99\n",
       "==========================================================================================\n",
       "Input size (MB): 0.20\n",
       "Forward/backward pass size (MB): 1194.92\n",
       "Params size (MB): 429.97\n",
       "Estimated Total Size (MB): 1625.09\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding dropout after activations.\n",
    "class NeuralNetwork_v1_6(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.feature_extraction = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3,3), padding='same'),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3,3), padding='same'),\n",
    "            nn.BatchNorm2d(num_features=32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3), padding='same'),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,3), padding='same'),\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), padding='same'),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3,3), padding='same'),\n",
    "            nn.BatchNorm2d(num_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3,3), padding='same'),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(3,3), padding='same'),\n",
    "            nn.BatchNorm2d(num_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=(3,3), padding='same'),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=(3,3), padding='same'),\n",
    "            nn.BatchNorm2d(num_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        self.dense_layers = nn.Sequential(\n",
    "            nn.Linear(in_features=28*28*512, out_features=256),\n",
    "            nn.BatchNorm1d(num_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=256, out_features=64),\n",
    "            nn.BatchNorm1d(num_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=10),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.feature_extraction(x)\n",
    "        logits = self.dense_layers(logits)\n",
    "        return logits\n",
    "\n",
    "model_v1_6 = NeuralNetwork_v1_6().to(device)\n",
    "summary(model_v1_6, input_size=(batch_size, 1, 28, 28))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ResNet                                   [64, 10]                  --\n",
       "├─Conv2d: 1-1                            [64, 64, 14, 14]          3,136\n",
       "├─BatchNorm2d: 1-2                       [64, 64, 14, 14]          128\n",
       "├─ReLU: 1-3                              [64, 64, 14, 14]          --\n",
       "├─MaxPool2d: 1-4                         [64, 64, 7, 7]            --\n",
       "├─Sequential: 1-5                        [64, 64, 7, 7]            --\n",
       "│    └─BasicBlock: 2-1                   [64, 64, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-1                  [64, 64, 7, 7]            36,864\n",
       "│    │    └─BatchNorm2d: 3-2             [64, 64, 7, 7]            128\n",
       "│    │    └─ReLU: 3-3                    [64, 64, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-4                  [64, 64, 7, 7]            36,864\n",
       "│    │    └─BatchNorm2d: 3-5             [64, 64, 7, 7]            128\n",
       "│    │    └─ReLU: 3-6                    [64, 64, 7, 7]            --\n",
       "│    └─BasicBlock: 2-2                   [64, 64, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-7                  [64, 64, 7, 7]            36,864\n",
       "│    │    └─BatchNorm2d: 3-8             [64, 64, 7, 7]            128\n",
       "│    │    └─ReLU: 3-9                    [64, 64, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-10                 [64, 64, 7, 7]            36,864\n",
       "│    │    └─BatchNorm2d: 3-11            [64, 64, 7, 7]            128\n",
       "│    │    └─ReLU: 3-12                   [64, 64, 7, 7]            --\n",
       "├─Sequential: 1-6                        [64, 128, 4, 4]           --\n",
       "│    └─BasicBlock: 2-3                   [64, 128, 4, 4]           --\n",
       "│    │    └─Conv2d: 3-13                 [64, 128, 4, 4]           73,728\n",
       "│    │    └─BatchNorm2d: 3-14            [64, 128, 4, 4]           256\n",
       "│    │    └─ReLU: 3-15                   [64, 128, 4, 4]           --\n",
       "│    │    └─Conv2d: 3-16                 [64, 128, 4, 4]           147,456\n",
       "│    │    └─BatchNorm2d: 3-17            [64, 128, 4, 4]           256\n",
       "│    │    └─Sequential: 3-18             [64, 128, 4, 4]           8,448\n",
       "│    │    └─ReLU: 3-19                   [64, 128, 4, 4]           --\n",
       "│    └─BasicBlock: 2-4                   [64, 128, 4, 4]           --\n",
       "│    │    └─Conv2d: 3-20                 [64, 128, 4, 4]           147,456\n",
       "│    │    └─BatchNorm2d: 3-21            [64, 128, 4, 4]           256\n",
       "│    │    └─ReLU: 3-22                   [64, 128, 4, 4]           --\n",
       "│    │    └─Conv2d: 3-23                 [64, 128, 4, 4]           147,456\n",
       "│    │    └─BatchNorm2d: 3-24            [64, 128, 4, 4]           256\n",
       "│    │    └─ReLU: 3-25                   [64, 128, 4, 4]           --\n",
       "├─Sequential: 1-7                        [64, 256, 2, 2]           --\n",
       "│    └─BasicBlock: 2-5                   [64, 256, 2, 2]           --\n",
       "│    │    └─Conv2d: 3-26                 [64, 256, 2, 2]           294,912\n",
       "│    │    └─BatchNorm2d: 3-27            [64, 256, 2, 2]           512\n",
       "│    │    └─ReLU: 3-28                   [64, 256, 2, 2]           --\n",
       "│    │    └─Conv2d: 3-29                 [64, 256, 2, 2]           589,824\n",
       "│    │    └─BatchNorm2d: 3-30            [64, 256, 2, 2]           512\n",
       "│    │    └─Sequential: 3-31             [64, 256, 2, 2]           33,280\n",
       "│    │    └─ReLU: 3-32                   [64, 256, 2, 2]           --\n",
       "│    └─BasicBlock: 2-6                   [64, 256, 2, 2]           --\n",
       "│    │    └─Conv2d: 3-33                 [64, 256, 2, 2]           589,824\n",
       "│    │    └─BatchNorm2d: 3-34            [64, 256, 2, 2]           512\n",
       "│    │    └─ReLU: 3-35                   [64, 256, 2, 2]           --\n",
       "│    │    └─Conv2d: 3-36                 [64, 256, 2, 2]           589,824\n",
       "│    │    └─BatchNorm2d: 3-37            [64, 256, 2, 2]           512\n",
       "│    │    └─ReLU: 3-38                   [64, 256, 2, 2]           --\n",
       "├─Sequential: 1-8                        [64, 512, 1, 1]           --\n",
       "│    └─BasicBlock: 2-7                   [64, 512, 1, 1]           --\n",
       "│    │    └─Conv2d: 3-39                 [64, 512, 1, 1]           1,179,648\n",
       "│    │    └─BatchNorm2d: 3-40            [64, 512, 1, 1]           1,024\n",
       "│    │    └─ReLU: 3-41                   [64, 512, 1, 1]           --\n",
       "│    │    └─Conv2d: 3-42                 [64, 512, 1, 1]           2,359,296\n",
       "│    │    └─BatchNorm2d: 3-43            [64, 512, 1, 1]           1,024\n",
       "│    │    └─Sequential: 3-44             [64, 512, 1, 1]           132,096\n",
       "│    │    └─ReLU: 3-45                   [64, 512, 1, 1]           --\n",
       "│    └─BasicBlock: 2-8                   [64, 512, 1, 1]           --\n",
       "│    │    └─Conv2d: 3-46                 [64, 512, 1, 1]           2,359,296\n",
       "│    │    └─BatchNorm2d: 3-47            [64, 512, 1, 1]           1,024\n",
       "│    │    └─ReLU: 3-48                   [64, 512, 1, 1]           --\n",
       "│    │    └─Conv2d: 3-49                 [64, 512, 1, 1]           2,359,296\n",
       "│    │    └─BatchNorm2d: 3-50            [64, 512, 1, 1]           1,024\n",
       "│    │    └─ReLU: 3-51                   [64, 512, 1, 1]           --\n",
       "├─AdaptiveAvgPool2d: 1-9                 [64, 512, 1, 1]           --\n",
       "├─Linear: 1-10                           [64, 10]                  5,130\n",
       "==========================================================================================\n",
       "Total params: 11,175,370\n",
       "Trainable params: 11,175,370\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 2.11\n",
       "==========================================================================================\n",
       "Input size (MB): 0.20\n",
       "Forward/backward pass size (MB): 44.05\n",
       "Params size (MB): 44.70\n",
       "Estimated Total Size (MB): 88.95\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "resnet18 = models.resnet18(weights='DEFAULT')\n",
    "num_ftrs = resnet18.fc.in_features\n",
    "resnet18.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "resnet18.fc = nn.Linear(num_ftrs, 10)\n",
    "resnet18.to(device)\n",
    "summary(resnet18, input_size=(batch_size, 1, 28, 28))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = {'train loss':[], 'train accuracy':[], 'val loss':[], 'val accuracy':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset) # Num of samples.\n",
    "    num_batches = len(dataloader) # Num of batches.\n",
    "    model.train() # set model to training mode.\n",
    "    epoch_loss, correct = 0, 0 # avg loss of the current epoch.\n",
    "    for batch, (X, y) in enumerate(dataloader): # FP and BP each batch of data.\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X) # \n",
    "        loss = loss_fn(pred, y) #\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad() # https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch\n",
    "        loss.backward() #\n",
    "        optimizer.step() #\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "        \n",
    "        \n",
    "    epoch_loss /= num_batches\n",
    "    correct /= size\n",
    "    history_dict['train loss'].append(epoch_loss)\n",
    "    history_dict['train accuracy'].append(100*correct)\n",
    "        \n",
    "        # save los"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = 0.0\n",
    "best_acc = 0.0\n",
    "curr_acc = 0.0\n",
    "def test(dataloader, model, loss_fn):\n",
    "    '''\n",
    "    Returns test accuracy.\n",
    "    '''\n",
    "    global test_loss\n",
    "    global best_acc\n",
    "    global curr_acc\n",
    "\n",
    "    size = len(dataloader.dataset) # Num of samples in the dataset.\n",
    "    num_batches = len(dataloader) # Num of batches.\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader: # X, y contain all the samples in the current batch.\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}\")\n",
    "    curr_acc = 100*correct\n",
    "    history_dict['val loss'].append(test_loss)\n",
    "    history_dict['val accuracy'].append(100*correct)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "\n",
    "def plot_Acc_And_Loss(model_name, history_dict, save=True):\n",
    "    \"\"\"\n",
    "    Plots loss and accuracy of train and val data over epochs.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    plt.plot(history_dict['train accuracy'])\n",
    "    plt.plot(history_dict['val accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    if save: \n",
    "        if not os.path.exists(f'model_logs/{model_name}_logs/'):\n",
    "            os.makedirs(f'model_logs/{model_name}_logs/')\n",
    "        plt.savefig(f'model_logs/{model_name}_logs/{model_name}_accuracy.png')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(history_dict['train loss'])\n",
    "    plt.plot(history_dict['val loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    if save: \n",
    "        if not os.path.exists(f'model_logs/{model_name}_logs/'):\n",
    "            os.makedirs(f'model_logs/{model_name}_logs/')\n",
    "        plt.savefig(f'model_logs/{model_name}_logs/{model_name}_loss.png')\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss and Optimizer\n",
    "Choco  \n",
    "Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_NAME = 't0'\n",
    "# save = True\n",
    "# model = NeuralNetwork_v1_6().to(device)\n",
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "# # lr = 100*1e-3\n",
    "# # optimizer = torch.optim.SGD(model.parameters(), lr=lr) # Stochastic gradient descent\n",
    "# # scheduler = ReduceLROnPlateau(optimizer=optimizer, factor=0.1, patience=2)\n",
    "# lr = 1e-3\n",
    "# optimizer = torch.optim.Adam(params=model.parameters(), lr=lr)\n",
    "# scheduler = ReduceLROnPlateau(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_loop(model_name, save, epochs, model, loss_fn, optimizer, scheduler):\n",
    "    global test_loss\n",
    "    global best_acc\n",
    "    global curr_acc\n",
    "    epoch = 1\n",
    "    print(\"Training\\n\")\n",
    "    for i in range(epochs):\n",
    "        print(f\"Epoch {i}\\n-------------------------------\")\n",
    "        train(dataloader=training_dataloader, model=model, loss_fn=loss_fn, optimizer=optimizer)\n",
    "        test(dataloader=test_dataloader, model=model, loss_fn=loss_fn)\n",
    "\n",
    "        if curr_acc > best_acc:\n",
    "            best_acc = curr_acc\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': test_loss,\n",
    "                'acc': best_acc\n",
    "            }, f\"models/{model_name}\")\n",
    "            print(f\"Saved model at Epoch: {epoch}, Test Acc: {best_acc}, to models/{model_name} \\n\")\n",
    "        \n",
    "        scheduler.step(test_loss)\n",
    "        epoch+=1\n",
    "    print(\"Training done!\\n\")\n",
    "\n",
    "    %matplotlib inline\n",
    "    plot_Acc_And_Loss(model_name, history_dict, save)\n",
    "    print(\"Plots saved.\\n\")\n",
    "\n",
    "    # model.load_state_dict(torch.load(f\"models/{MODEL_NAME}\"))\n",
    "    checkpoint = torch.load(f\"models/{model_name}\")\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "\n",
    "    classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "    ]\n",
    "\n",
    "    model.eval()\n",
    "    for sample in range(0, 10):\n",
    "        x, y = test_data[sample][0], test_data[sample][1] # get 1st sample and corresponding label.\n",
    "        with torch.no_grad():\n",
    "            x = torch.unsqueeze(x, 0)\n",
    "            pred = model(x.to(device))\n",
    "            predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "            print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "\n",
      "Epoch 0\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\envs\\pytorchenv\\lib\\site-packages\\torch\\nn\\modules\\container.py:204: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.303935  [    0/60000]\n",
      "loss: 2.303555  [ 6400/60000]\n",
      "loss: 2.303809  [12800/60000]\n",
      "loss: 2.302708  [19200/60000]\n",
      "loss: 2.303348  [25600/60000]\n",
      "loss: 2.302932  [32000/60000]\n",
      "loss: 2.302087  [38400/60000]\n",
      "loss: 2.302583  [44800/60000]\n",
      "loss: 2.302677  [51200/60000]\n",
      "loss: 2.301754  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.302656\n",
      "Saved model at Epoch: 1, Test Acc: 10.0, to models/model_v1 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.305325  [    0/60000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\envs\\pytorchenv\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:163: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.303368  [ 6400/60000]\n",
      "loss: 2.302685  [12800/60000]\n",
      "loss: 2.301113  [19200/60000]\n",
      "loss: 2.301823  [25600/60000]\n",
      "loss: 2.302423  [32000/60000]\n",
      "loss: 2.302868  [38400/60000]\n",
      "loss: 2.303358  [44800/60000]\n",
      "loss: 2.302201  [51200/60000]\n",
      "loss: 2.301037  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.302627\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.303013  [    0/60000]\n",
      "loss: 2.301439  [ 6400/60000]\n",
      "loss: 2.301647  [12800/60000]\n",
      "loss: 2.301176  [19200/60000]\n",
      "loss: 2.302931  [25600/60000]\n",
      "loss: 2.304185  [32000/60000]\n",
      "loss: 2.298985  [38400/60000]\n",
      "loss: 2.303960  [44800/60000]\n",
      "loss: 2.303170  [51200/60000]\n",
      "loss: 2.302958  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.302647\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.304871  [    0/60000]\n",
      "loss: 2.303468  [ 6400/60000]\n",
      "loss: 2.302635  [12800/60000]\n",
      "loss: 2.302093  [19200/60000]\n",
      "loss: 2.303209  [25600/60000]\n",
      "loss: 2.303307  [32000/60000]\n",
      "loss: 2.303186  [38400/60000]\n",
      "loss: 2.302901  [44800/60000]\n",
      "loss: 2.303740  [51200/60000]\n",
      "loss: 2.303559  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.302651\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.303593  [    0/60000]\n",
      "loss: 2.304730  [ 6400/60000]\n",
      "loss: 2.302170  [12800/60000]\n",
      "loss: 2.301945  [19200/60000]\n",
      "loss: 2.302331  [25600/60000]\n",
      "loss: 2.301399  [32000/60000]\n",
      "loss: 2.302469  [38400/60000]\n",
      "loss: 2.302406  [44800/60000]\n",
      "loss: 2.302356  [51200/60000]\n",
      "loss: 2.302586  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.302641\n",
      "Training done!\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plots saved.\n",
      "\n",
      "Predicted: \"Trouser\", Actual: \"Ankle boot\"\n",
      "Predicted: \"Trouser\", Actual: \"Pullover\"\n",
      "Predicted: \"Trouser\", Actual: \"Trouser\"\n",
      "Predicted: \"Trouser\", Actual: \"Trouser\"\n",
      "Predicted: \"Trouser\", Actual: \"Shirt\"\n",
      "Predicted: \"Trouser\", Actual: \"Trouser\"\n",
      "Predicted: \"Trouser\", Actual: \"Coat\"\n",
      "Predicted: \"Trouser\", Actual: \"Shirt\"\n",
      "Predicted: \"Trouser\", Actual: \"Sandal\"\n",
      "Predicted: \"Trouser\", Actual: \"Sneaker\"\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "# optimizer = torch.optim.Adam(params=model.parameters(), lr=lr)\n",
    "optimizer = torch.optim.SGD(resnet18.parameters(), lr=lr, momentum=0.9) # Stochastic gradient descent\n",
    "# scheduler = ReduceLROnPlateau(optimizer=optimizer)\n",
    "scheduler = StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "train_test_loop(\n",
    "    model_name='model_v1',\n",
    "    save=True,\n",
    "    epochs=5,\n",
    "    model=model_v1,\n",
    "    loss_fn=nn.CrossEntropyLoss(),\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c6c275773e72c8139dcc50bab8fed0f3c21339770908214266967315dfdb557"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
